- 音響学会(3/9(水))
  - （招待講演）二者間コミュニケーションの行動と脳機能：機械学習と情報論的分析を用いて   皆川 泰代(慶應義塾大学)
    - 母子の二者間相互作用を研究
    - 相互作用中の脳の動きを見る
    - 社会脳はお互いに同期している、脳のSTG・MTGの部分
    - 一緒に歌ったりするとよく脳は同期するが、別のことをしている時にはどうなるのか
      - 協力条件では脳の同期は高い、一人で活動しているときは個人内の脳同期結合が起こる
      - 片方が顔を上げたときに大きな脳の同期が見られた。脳のTP・JLPFCの部分
    - 顔の動きが同期していたことが39ペア中24ペアで見られた
    - 違反文法を学習している時には、新生児の脳機能結合が弱くなっている。
***
  - （招待講演）認知・行動科学のための機械学習○森田 尭(大阪大学・産業科学研究所)
    - 動物の音声認識は限定的
    - 普通の音声認識は教師あり学習であるため、文字起こしと音声を一致させていく
    - 教師なし学習、音声のみを受け取って学習する。動物の音声認識に使えるかも。一貫したラベリングができる
    - 段階に分けた分析ではなく、End-to-Endの分析へが多くなっている。特徴量の抽出やセグメンテーションの分析も一貫して行うことが増えている。全てニューラルネットワークに入れることで分析している
    - 音響的特徴量のクラスタリングが難しい,母音にも前の子音によって様々になっているため
       - 最近ではフレームレベルで分類している
***
  - 招待講演）Machine Speech Chain による音声聴取生成システムのモデル化の試み ○中村 哲(奈良先端大)
    - Speech Chainヶ起こる現象の原因としてLombard Effectがある
      - Lombard Effectとは、雑音下で自分の声が聞こえるように音声のIntensityをあげ、Foを高い方へと修正する。発話速度を調整する。音声を変形していく
    - 遅延聴覚フィードバック(DAF)によって吃音を治療することができる
    - 健常者にDAFを使うことで脳内メカニズムを調べている、DAFを使うとしゃべりにくくなる
    - End-to-End音声認識、音声合成モデルを連結し誤差を伝播して学習、音声認識と合成でぐるぐる回す。実際にはなかなか難しい
    - これがSpeech Chainの工学的適用
    - Speaker Embeddingによって様々な話者性を付与することで、多人数の対話を再現できる
    - 音声合成、音声認識を上手に繋ぐことができる
    - 実際に音声認識、合成するときにSpeech Chainによるフィードバックを使い
***
  - 非流暢ラベルを用いた言い淀み整形End-to-End音声認識☆堀井 こはる(豊橋技科大)，福田 芽衣子(徳島大)，太田 健吾(阿南高専)，西村 良太(徳島大)，小川 厚徳(NTT)，北岡 教英(豊橋技科大)
    - 言い淀みやフィラーを「@」や「＃」としたラベルにすることで認識できるようにする
    - このラベルを除去することで話者が伝えたい文章のみを抽出できる
    - 言い淀みがある音声をない音声に整形することが目的
    - 「えーいじあっ以上で大体発表終わります」を「以上で大体発表終わります」にすることができる

***
  - 印象表現語ラベルを用いたFader Networksに基づく音声印象変換☆岡留 有希，大西 弘太郎，岸田 拓也，中鹿 亘(電通大)
    - 声の聞こえの印象を形容詞で表し、この形容詞を変換することで音声
    - 印象ラベル7種類形容詞(木戸らが表した声質に関わるもの)の対から構成され-3から3の実数で表される
***
  - Period-HiFi-GAN: 基本周波数を制御可能な高速ニューラルボコーダ◎松原 圭亮(神戸大/NICT)，岡本 拓麿(NICT)，高島 遼一，滝口 哲也(神戸大)，戸田 智基(名大/NICT)，河井 恒(NICT)
    - 音声変換の従来手法、ソースフィルターモデリング、声帯と口付近に分けるもの
    - Foを変えた時の機械的な音が減っていた。女性音声をさらに高くすると自然ではなくなった。
***
  - 読唇における連続発話時の個人性表出の検討☆菅原 直人，木戸 博(東北工大)
    - 健常者の読唇推定成功率30%、先天性失聴者は20%
    - 母音の「あ、い、え」の口の動きには個人差があるといえる
    - 口の開きによって「あ、い、え」(いとえは近い、方言では方言では同化していることがある)「う、お」にクラスタリング分類できた
    - 連続発話でも個人差が大きくなることが確認できた
    - 長音からも個人差が確認できた
***
  - 高精度な話者照合のためのTransformerを用いた話者特徴量抽出◎板倉 光佑，△畠中 亮太，△大毛 勝統，△福田 鉄平，△岡田 慎太郎(Panasonic)
    - 話者識別：話者が誰であるかを識別する、議事録作成に使える
    - 話者照合：話者が特定の人物と一致するかを調べる。一致であるか不一致であるかを返す。セキュリティなどに使える
    - 話者特徴量を抽出する。近年DNNを用いた抽出方法が台頭(時系列データの処理がフレーム単位の処理で考慮されていない)
      - x-vectorが話者特徴量の抽出方法の主流
      - TDNN(Time delay neural network)をフレーム単位に使う
    - キーアイデア:入力全体を俯瞰して処理できる構造が必要→AttentionベースのモデルであるTransformerを使用
***
  - 人名想起課題における非流暢性の調音運動観察○林　 良子，孫 静(神戸大)，北村 達也(甲南大)，△定延 利之(京都大)
    - 発話態度と、つっかえ方が連動している(先行研究「つっかえを発話パタンとして認定させる話し手の能力」定延)
    - 超音波と音声の分析をした
    - その他に力みごえ、囁き声、文末上昇、空気啜り入れている
    - 途切れが一番出てくる　← 会話ではないため異なってきているのかも?

***
  - 畳み込みニューラルネットワークを用いたサウンドスペクトログラムからの声道断面積関数推定に関する一考察○松﨑 博季，△千葉 拓弥，△和田 直史，△竹沢 恵，△真田 博文(北科大)
    - 声道などをMRI・CT・胃カメラで撮影するのはコストや負担が大きい
    - 音声データのみで声道などを推定したい。これはよく行われている。多層ニューラルネットワークを使って声道断面積関数を推定する
    - 声道断面積関数を使って音を作り、そのスペクトログラムから逆推定する
***
  - 声道模型の動きを制御する試み○荒井 隆行(上智大)
    - 梅田・寺西式声道模型を改良した
      - 梅田寺西式、口腔に11本、鼻腔に8本の角棒を使い形を変形させて音を再現する
    - 母音の「い」から母音の「あ」に高速で移動させることで接近音に近いおとを作ることができた
    - 鼻音を想起させるような音も生成できた
***
  - 演技音声に対する話者感情推定におけるセリフの違いの影響の分析☆宮本 侑季，竹澤 寿幸，目良 和也，△黒澤 義明(広島市立大学)
    - 感情認識としては、言語情報の影響を受けていた
    - 嬉しそうに「全然嬉しくない」と言った時に、嬉しくないと判断される傾向があった
    - 感情音声を作る時には中立的な言葉である必要があると考えられる。
    - セリフと感情を伝えて発生してもらった
    - リテイクの基準も難しい(感情を音声に表せているのか判断するのが難しい)

***
  - 大浦さんへの質問
     - 1回目
       - 東京大学 峯松先生から「1.たとえば、外国語の教育に中学生50人に指導する時を想定するとどうするか。今後どうするのか?2.オプティカルフローの処理を矢印で記しているが、あえて動画の上にオプティカルフローを乗せた効果、意義は何なのか」
       - 近畿大学　勝瀬先生から「小学生への発音訓練を想定したものであると捉えて良いのか?リアルな模型を持っていくだけでも小学生は嫌がることがある。MRI画像を舌の動きだとすら思えないと感じている。もっとデフォルメしたものにできないのか?子ども画像と照らし合わせてここが違うと示せたら良いと思った」
       - 東京理科大学 桂田先生から「最後の矢印の画像にするためにはどのようなことをすれば良いと考えていますか?」「千葉工大の竹本先生のところで輪郭を使っているものがある。MRIはぼんやりとして見ずらいため、竹本先生のもが参考になるのではないか」「先ほど発話者の音声からMRI画像を見れた方が良いという話があったが、MRI動画像の生成をやったことある学生がうまくいっていたものがある、作ることができたものがある」
     - 3回目?
       - 上智大学荒井先生から「オプティカルフローを大雑把に表示できれば良いのか?手書きで書いているものはオプティカルフローを見た結果書いたものなのか?オプティカルフローをどのようにシンプルに表示させるのか、案はあるのか?オプティカルフロー自身の妥当性はどのように検証するのか、どのようにするべきなのか?」
       - 埼玉大学 ソヌミ先生から「なかなか見せるだけで自分の発音を見直すには至らない、MRIの動きを理解したとしても難しいそう。自分の動きとの違いが分からないと難しそう。画像と自分の動きとの差異を知ることでフィードバックになるのではないかと感じた」
     - 4回目?
       - 筑波技大学 安先生から「差分を取ってフローを表示するのは良い方法だと感じた。差分を取った時間は妥当なものであるのか」
***

***
- 3月10日(木)
  - 音響特徴量の操作による癒やされる音声の生成に関する一検討☆渡邊 悠希，坂本 修一(東北大学)，星 貴之，長谷 芳樹，△中野 学(ピクシーダストテクノロジーズ(株))
    - メル周波数ケプとラム係数(MFCC)から得られると癒しに相関がある
    - 変化させた音響特徴量、基本周波数(Fo)の平均・スペクトルの伸縮・時間長・Foの変化幅・スペクトル傾斜の5種類を5段階に変化させた
    - 話速を遅くする方、Foの変化幅が大きい　(抑揚が大きい)方の回答が多かった
    - 癒される音声に期待する話速は6mora/sである
    - 男性聴取者と女性聴取者に違いが出た
***
  - 宣伝音声の話者と聴取者の属性が感情を媒介とした購買意欲モデルに対して及ぼす影響◎長野 瑞生，井島 勇祐，廣谷 定男，△戸田 浩之(NTT)
    - 平均Fo、Fo分散、話速を変化させることが感情に与える影響がある
    - 感情(快-不快、覚醒-睡眠、支配-服従)
    - 音声が感情に与える影響、さらに感情が購買意欲に与える影響を調べている
    - Scott 2016
    - 聴取者は50代を境に反応が変化しいた、女性聴取者の方が性別の影響が受けやすい
***
  - 室内の残響時間と音声明瞭度の関係性に関する理論的検討☆廣瀬 量子(東大・新領域)，佐久間 哲哉(東大・工)
    - 残響時間、平均吸音率と明瞭性との関係を明らかにする

***
  - 日本語話者による日本語感情音声の知覚：知覚感情・韻律的特徴・声質に注目して☆中島 彩子(法政大学大学院人文科学研究科心理学専攻)，田嶋 圭一(法政大学文学部)
    - 話者が意図して感情表出した音声から、聴者はどのように知覚するのかを調べた
    - 喜び、嫌悪、悲しみ、恐れ、怒りの感情音声を発生させて、実験を行った
    - 韻律心理量、声質評定を質問しに回答してもらった
    - 喜びと悲しみにおいては感情の混同は見られなかった。おそれの音声は悲しみと混同した。嫌悪は怒りと混同した。怒りの音声は性差が出た、男性は混同
    - 混同はなぜ起こるのか
      - 重回帰分析の要素である「冷たさ、激しさ、低さ」などの特徴が類似しているためではないか

***
  - 音素・話速情報を利用した異なる発話スタイル間のノンパラレル声質変換の検討☆金垣 葵，能勢 隆，伊藤 彰則(東北大院・工学研)
    - スタイルを変更させた音声は明瞭が悪くなるという問題がある
    - 話速合わせ、言語情報の損失関数用いるなどを行うと明瞭性を向上することができた

***
  - 注意機構付きVAEを用いた日本語テキストの発話スタイル変換☆吉岡 大貴，安田 裕介(名大)，松永 悟行，大谷 大和((株)エーアイ)，戸田 智基(名大)
    - フィラーや言い淀みを含む音声を用いた（CSJ）
    - フィラーや言い淀みを付与する返還は失敗した
    - ラベル情報だけで変換するとスタイルの表現力が不足
    - 言い淀みを除いたものと、関西語のコーパスで、方言の変換を行った
***
  - 音響情報と言語情報を利用した短区間の音声感情認識☆永瀬 亮太郎，福森 隆寛，山下 洋一(立命館大・情報理工)
    - 3秒単位の音声感情認識の認識率が最大約5~13%向上した
    - 音声感情認識はヒューマンコンピュータインタラクションの分野で注目されている
    - 発話を数秒単位で区切った音声、短区間での感情認識
    - 待ち時間が少なく、リアルタイムの認識ができる
    - 音響情報と言語情報両方を含めた感情認識を行った
    - 音響情報はlog power spectrogram 言語情報にはBERTの埋め込み表現を利用

***
- 3月11日(金)
  - 日本語母語話者および日本語学習者による疑問・非疑問発話の韻律特徴：平均ピッチ曲線を用い比較◎波多野 博顕(筑波大)，△王 可心，△陳 凱僑(神戸大院)，林 良子(神戸大)
    - 母語の特性が日本語音声に影響がある
    - 外国語訛りは韻律特徴に影響
    - 自然さの評価には韻律の影響が大きい
    - 母語別の音声から「平均ピッチ曲線」を構築することで、典型的な韻律動態を記述し、その異同を調べる
    - 学習者はピッチの山をうまく表現できていない結果

***
  - Speech laughが発生しやすい調音に関する対話ドメイン依存性の検証☆阿部 将士，有本 泰子(千葉工大)
    - Speech laugh発話中に突発的に起こる笑いのこと
    - iとeで発生しやすいd,g,tで発生しやすい(ゲーム場面に依存した可能性がある「死ぬ死ぬ死ぬ死ぬなど言っているからかも」)
    - 対話形式「雑談」関係性を「知人。家族のみ」 CEJCは216こ
    - 日本語話し言葉コーパスの分節音ラベリングに準拠
    - CEJCとOGVCのコーパス比較を行なっている
    - 分析方法が参考になりそう
***
  - 音声認識結果による言語特徴と音響特徴による音声感情認識の検討☆櫻井 美咲，△須々田 和基，小坂 哲夫(山形大)
    - 音響特徴：韻律情報やスペクトル
    - 言語特徴を併用している
    - 発話全体から音響特徴を抽出　時系列特徴：発話中で局所的に表出される感情特徴を抽出
    - 
***
  - 非言語情報知覚における音声の振幅包絡線情報の役割：人工内耳装用者に対する検討○鵜木 祐史，△朱 治，木谷 俊介(JAIST)，△荒木 友希子(金沢大)
    - 言語情報の知覚にとっては4Hz以上が重要(Zhu et all 2018a)
    - 話者性の知覚にとっては8Hz以上が重要
    - 
    - 
***
  -
    - メルケプストラムの特徴量は音声の移り変わりを意味する
    - 
    - 
    - 
***
  -
    - 
    - 
    - 
    - 
***
